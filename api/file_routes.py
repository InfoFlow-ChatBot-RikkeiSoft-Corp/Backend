from flask import Blueprint, request, jsonify
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_core.documents import Document
from services.answer_generator import AnswerGenerator
from services.document_fetcher import DocumentFetcher
from services.vector_db_manager import VectorDBManager
from services.retriever_manager import RetrieverManager
from services.chat_generator import ChatGenerator
from services.chat_service import ChatService
from services.RAG_manager import RAGManager
from werkzeug.utils import secure_filename
from datetime import datetime
from models.models import db, FileMetadata,User, WeblinkMetadata
from services.document_fetcher import DocumentFetcher
from services.vector_db_manager import VectorDBManager
import sqlalchemy as sa
from pytz import timezone
from werkzeug.utils import secure_filename
from dotenv import load_dotenv
import os
from urllib.parse import unquote
import re

# Load environment variables
load_dotenv()

# Get API keys from environment variables
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")

from dotenv import load_dotenv
import os
import uuid

file_routes = Blueprint('file_routes', __name__)

ALLOWED_FILE_TYPES = {'txt', 'docx', 'pdf'}
MAX_FILE_SIZE = 25 * 1024 * 1024  # 25 MB

tz = timezone("Asia/Ho_Chi_Minh")  # Replace with your desired time zone
current_time = datetime.now(tz)
document_fetcher = DocumentFetcher()
vector_db_manager = VectorDBManager(
    openai_api_key=OPENAI_API_KEY,
    google_api_key=GOOGLE_API_KEY
)

# Get API keys from environment variables
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")

# Ensure at least one API key is provided
if not (GOOGLE_API_KEY or OPENAI_API_KEY):
    raise ValueError("Neither GOOGLE_API_KEY nor OPENAI_API_KEY is set in the environment variables.")

answer_generator = AnswerGenerator(
    model="models/gemini-1.5-flash", 
    temperature=0.7               
)
retriever_manager = RetrieverManager(vector_db_manager=vector_db_manager)
rag_manager = RAGManager(
    retriever_manager=retriever_manager,
    answer_generator=answer_generator,
    document_fetcher=document_fetcher,
    vector_db_manager=vector_db_manager
)


def is_allowed_file(file_name):
    return '.' in file_name and file_name.rsplit('.', 1)[1].lower() in ALLOWED_FILE_TYPES

def is_admin(username):
    result = db.session.execute(
        sa.text("SELECT role FROM company_employee WHERE email = :email"),
        {'email': username}
    ).mappings().fetchone()

    return result and result['role'] == 'admin'

@file_routes.route('/upload', methods=['POST'])
def upload_file():
    username = request.headers.get('username')
    print(f"\n=== ğŸ“¤ Upload Request Debug Info ===")
    print(f"Username: {username}")
    
    if not username:
        return jsonify({"error": "Username not provided"}), 400

    if not is_admin(username):
        return jsonify({"error": "Access denied. Only admins can upload content."}), 403

    user = User.query.filter_by(username=username).first()
    if not user:
        print(f"âŒ User not found: {username}")
        return jsonify({"error": "User not found"}), 404

    print(f"âœ… User authenticated: {username}")

    # íŒŒì¼ ì—…ë¡œë“œ ì²˜ë¦¬
    if 'file' in request.files:
        print("ğŸ“‚ Processing file upload")
        file = request.files['file']
        
        if file.filename == '':
            print("âŒ No file selected")
            return jsonify({"error": "No selected file"}), 400

        if not is_allowed_file(file.filename):
            return jsonify({"error": "File type not allowed"}), 400

        # íŒŒì¼ í¬ê¸° ì²´í¬
        file.seek(0, 2)
        file_size = file.tell()
        file.seek(0)
        
        if file_size > MAX_FILE_SIZE:
            print(f"âŒ File too large: {file_size} bytes")
            return jsonify({"error": "File exceeds maximum size of 25 MB"}), 400

        try:
            print(f"ğŸ“„ Processing file: {file.filename}")
            
            # íŒŒì¼ ë©”íƒ€ë°ì´í„° ì €ì¥
            file_metadata = FileMetadata(
                name=file.filename,
                size=file_size,
                type=file.filename.rsplit('.', 1)[1].lower(),
                upload_date=current_time,
                user_id=user.id
            )
            db.session.add(file_metadata)
            db.session.commit()
            print(f"âœ… File metadata saved: {file_metadata.id}")

            # íŒŒì¼ ì²˜ë¦¬ ë° ë²¡í„° ì €ì¥
            temp_path = os.path.join("temp_uploads", secure_filename(file.filename))
            file.save(temp_path)
            print(f"âœ… File saved to temp location: {temp_path}")

            docs = []
            file_extension = file.filename.rsplit('.', 1)[1].lower()
            if file_extension == 'docx':
                docs = document_fetcher.load_docx(temp_path)
            elif file_extension == 'pdf':
                docs = document_fetcher.load_pdf(temp_path)
            elif file_extension == 'txt':
                docs = document_fetcher.load_txt(temp_path)

            if not docs:
                print("âŒ Failed to process document")
                db.session.delete(file_metadata)
                db.session.commit()
                return jsonify({"error": "Failed to process document"}), 500

            print(f"âœ… Document processed successfully")
            vector_db_manager.vectorstore.add_documents(docs)
            vector_db_manager.vectorstore.save_local(vector_db_manager.vectorstore_path)
            print(f"âœ… Document added to vector store")

            return jsonify({
                "message": "File uploaded successfully",
                "metadata": {
                    "id": file_metadata.id,
                    "name": file_metadata.name,
                    "size": file_metadata.size,
                    "type": file_metadata.type,
                    "upload_date": file_metadata.upload_date.isoformat()
                }
            }), 201

        except Exception as e:
            db.session.rollback()
            print(f"âŒ Error processing file: {str(e)}")
            return jsonify({"error": f"An error occurred: {str(e)}"}), 500

    # URL ì—…ë¡œë“œ ìš”ì²­ ì²˜ë¦¬
    elif ('title' in request.form and 'url' in request.form) or request.is_json:
        print("ğŸ“ Processing URL upload request")
        
        if request.is_json:
            data = request.get_json()
            url = data.get("url", "").strip()
            title = data.get("title", "").strip()
            print(f"ğŸ“ Original JSON data - title: {title}, url: {url}")
            
            # URLì´ ê°ì²´ì¸ ê²½ìš° ì‹¤ì œ URL ì¶”ì¶œ
            if isinstance(url, dict):
                if 'url' in url:
                    url = url['url']
                elif 'title' in url:
                    url = url['title']
            
            # titleì´ ë¹„ì–´ìˆëŠ” ê²½ìš° URLì—ì„œ ì œëª© ìƒì„±
            if not title:
                # URL ê²½ë¡œì˜ ë§ˆì§€ë§‰ ë¶€ë¶„ì„ titleë¡œ ì‚¬ìš©
                from urllib.parse import urlparse
                path = urlparse(url).path
                title = path.split('/')[-1].replace('-', ' ').title()
                if not title:  # ê²½ë¡œê°€ ë¹„ì–´ìˆëŠ” ê²½ìš°
                    title = urlparse(url).netloc
                print(f"ğŸ“ Generated title from URL: {title}")

            print(f"ğŸ“ Processed data - title: {title}, url: {url}")
            
            if not url:
                return jsonify({"error": "URL is required"}), 400

            try:
                # ì¤‘ë³µ ì²´í¬
                existing_weblink = WeblinkMetadata.query.filter_by(url=url).first()
                if existing_weblink:
                    print(f"âš ï¸ Weblink already exists: {url}")
                    return jsonify({
                        "error": "This URL has already been uploaded"
                    }), 400
                    
                # ì›¹ë§í¬ ë©”íƒ€ë°ì´í„° ìƒì„±
                weblink = WeblinkMetadata(
                    title=title[:1000] if len(title) > 1000 else title,
                    url=url[:1000] if len(url) > 1000 else url,
                    user_id=user.id,
                    upload_date=current_time,
                    description="Uploaded via web interface"
                )
                
                print(f"ğŸ“ Creating weblink metadata for user_id: {user.id}")
                db.session.add(weblink)
                db.session.commit()
                print(f"âœ… Weblink metadata saved with ID: {weblink.id}")

                # Fetch and process the document
                print(f"ğŸ“ Fetching document from URL: {url}")
                doc = document_fetcher.fetch(title, url)
                if not doc:
                    print(f"âŒ Failed to fetch document from URL: {url}")
                    db.session.delete(weblink)
                    db.session.commit()
                    return jsonify({"error": "Failed to fetch document content"}), 400

                # Add to vector store
                print("ğŸ“ Adding document to vector store")
                vector_details = vector_db_manager.add_doc_to_db(doc)
                print(f"âœ… Document added to vector store: {vector_details}")

                return jsonify({
                    "message": "Weblink uploaded successfully",
                    "metadata": weblink.to_dict(),
                    "vector_details": vector_details
                }), 200

            except Exception as e:
                db.session.rollback()
                error_msg = f"Error processing URL: {str(e)}"
                print(f"âŒ {error_msg}")
                print(f"âŒ Exception type: {type(e)}")
                print(f"âŒ Exception details: {str(e)}")
                return jsonify({"error": error_msg}), 500

        else:
            title = request.form.get("title", "").strip()
            url = request.form.get("url", "").strip()

        print(f"ğŸ“ Processed data - title: {title}, url: {url}")

        if not title or not url:
            return jsonify({"error": "Both title and URL are required"}), 400

        try:
            # URL ë¬¸ìì—´ì—ì„œ ì‹¤ì œ URL ì¶”ì¶œ (ë”°ì˜´í‘œë¡œ ë‘˜ëŸ¬ì‹¸ì¸ URL ì¶”ì¶œ)
            url_match = re.search(r'https?://[^\s\'"]+', url)
            if url_match:
                url = url_match.group(0)
            
            print(f"ğŸ“ Final URL: {url}")

            # URLì´ ì‹¤ì œ URL í˜•ì‹ì¸ì§€ í™•ì¸
            if not url.startswith(('http://', 'https://')):
                print(f"âŒ Invalid URL format: {url}")
                return jsonify({"error": "Invalid URL format. URL must start with http:// or https://"}), 400

            # titleì—ì„œ ì‹¤ì œ URLì´ë‚˜ ì œëª© ì¶”ì¶œ
            if isinstance(title, str):
                # URLì´ í¬í•¨ëœ ê²½ìš° URL ì¶”ì¶œ
                url_in_title = re.search(r'https?://[^\s\'"]+', title)
                if url_in_title:
                    title = url_in_title.group(0)
                else:
                    # ê°ì²´ í˜•íƒœì˜ ë¬¸ìì—´ì—ì„œ title ë˜ëŠ” url ê°’ ì¶”ì¶œ
                    title_match = re.search(r'title\s*:\s*"([^"]+)"', title)
                    if title_match:
                        title = title_match.group(1)
                    else:
                        # ê¸°ë³¸ê°’ìœ¼ë¡œ URLì˜ ë§ˆì§€ë§‰ ë¶€ë¶„ ì‚¬ìš©
                        title = url.split('/')[-1]

            print(f"ğŸ“ Final title: {title}")

            # ì¤‘ë³µ ì²´í¬
            existing_weblink = WeblinkMetadata.query.filter_by(url=url).first()
            if existing_weblink:
                print(f"âš ï¸ Weblink already exists: {url}")
                return jsonify({
                    "error": "This URL has already been uploaded"
                }), 400
                
            # ì›¹ë§í¬ ë©”íƒ€ë°ì´í„° ìƒì„±
            weblink = WeblinkMetadata(
                title=title[:1000] if len(title) > 1000 else title,
                url=url[:1000] if len(url) > 1000 else url,
                user_id=user.id,
                upload_date=current_time,
                description="Uploaded via web interface"
            )
            
            print(f"ğŸ“ Creating weblink metadata for user_id: {user.id}")
            db.session.add(weblink)
            db.session.commit()
            print(f"âœ… Weblink metadata saved with ID: {weblink.id}")

            # Fetch and process the document
            print(f"ğŸ“ Fetching document from URL: {url}")
            doc = document_fetcher.fetch(title, url)
            if not doc:
                print(f"âŒ Failed to fetch document from URL: {url}")
                db.session.delete(weblink)
                db.session.commit()
                return jsonify({"error": "Failed to fetch document content"}), 400

            # Add to vector store
            print("ğŸ“ Adding document to vector store")
            vector_details = vector_db_manager.add_doc_to_db(doc)
            print(f"âœ… Document added to vector store: {vector_details}")

            return jsonify({
                "message": "Weblink uploaded successfully",
                "metadata": weblink.to_dict(),
                "vector_details": vector_details
            }), 200

        except Exception as e:
            db.session.rollback()
            error_msg = f"Error processing URL: {str(e)}"
            print(f"âŒ {error_msg}")
            print(f"âŒ Exception type: {type(e)}")
            print(f"âŒ Exception details: {str(e)}")
            return jsonify({"error": error_msg}), 500

    else:
        return jsonify({"error": "Invalid request. Provide a file or title and URL."}), 400


@file_routes.route('/list_files', methods=['GET'])
def list_files():
    username = request.headers.get('username')
    if not username:
        return jsonify({"error": "Username not provided"}), 400

    if not is_admin(username):
        return jsonify({"error": "Access denied. Only admins can view files."}), 403

    print("\n=== ğŸ“ File Listing Debug Info ===")
    print(f"Request from username: {username}")

    sort_by = request.args.get('sort_by', 'upload_date')
    sort_order = request.args.get('order', 'desc')
    is_url = request.args.get('is_url', '').lower() == 'true'  # URL íŒŒë¼ë¯¸í„° ì¶”ê°€
    print(f"Sort parameters - by: {sort_by}, order: {sort_order}")
    print(f"is_url parameter: {is_url}")

    try:
        documents = []

        if is_url:
            # ì›¹ë§í¬ ë©”íƒ€ë°ì´í„° ì¿¼ë¦¬
            weblinks_query = WeblinkMetadata.query
            if sort_by in ['title', 'upload_date']:
                sort_field = 'title' if sort_by == 'name' else sort_by
                weblinks_query = weblinks_query.order_by(
                    getattr(WeblinkMetadata, sort_field).desc() if sort_order == 'desc' 
                    else getattr(WeblinkMetadata, sort_field)
                )
            weblinks = weblinks_query.all()
            print(f"ğŸ”— Found {len(weblinks)} weblinks in database")

            # ì›¹ë§í¬ ë©”íƒ€ë°ì´í„° ì¶”ê°€
            for weblink in weblinks:
                doc = {
                    "title": weblink.url,
                    "type": "weblink",
                    "url": weblink.url,
                    "upload_date": weblink.upload_date.isoformat()
                }
                documents.append(doc)
                print(f"ğŸŒ Added weblink: {weblink.url}")

        else:
            # íŒŒì¼ ë©”íƒ€ë°ì´í„° ì¿¼ë¦¬
            files_query = FileMetadata.query
            if sort_by in ['name', 'size', 'type', 'upload_date']:
                files_query = files_query.order_by(
                    getattr(FileMetadata, sort_by).desc() if sort_order == 'desc' 
                    else getattr(FileMetadata, sort_by)
                )
            files = files_query.all()
            print(f"ğŸ“‚ Found {len(files)} files in database")

            # íŒŒì¼ ë©”íƒ€ë°ì´í„° ì¶”ê°€
            for file in files:
                doc = {
                    "title": file.name,
                    "type": "file",
                    "size": file.size,
                    "file_type": file.type,
                    "upload_date": file.upload_date.isoformat()
                }
                documents.append(doc)
                print(f"ğŸ“„ Added file: {file.name} ({file.type})")

        print(f"\nğŸ“Š Total documents in response: {len(documents)}")
        if is_url:
            print(f"Weblinks: {len(documents)}")
        else:
            print(f"Files: {len(documents)}")
        print("=== End Debug Info ===\n")

        return jsonify({"files": documents}), 200
    except Exception as e:
        print(f"âŒ Error in list_files: {str(e)}")
        return jsonify({"error": f"Database error: {str(e)}"}), 500

@file_routes.route('/delete/<path:title>', methods=['DELETE'])
def delete_file(title):
    """
    ì œëª©ì„ ê¸°ì¤€ìœ¼ë¡œ ë©”íƒ€ë°ì´í„°ì™€ ë²¡í„° ë°ì´í„°ë¥¼ ë™ê¸°í™”í•˜ì—¬ ì‚­ì œ
    """
    decoded_title = unquote(title)
    print(f"Received DELETE request for title: {decoded_title}")
    
    username = request.headers.get('username')
    if not username:
        print("Error: Username not provided")
        return jsonify({"error": "Username not provided"}), 400
 
    if not is_admin(username):
        print(f"Access denied for user: {username}")
        return jsonify({"error": "Access denied. Only admins can delete files."}), 403
 
    try:
        # URLì¸ ê²½ìš° WeblinkMetadataì—ì„œ URLë¡œ ê²€ìƒ‰
        weblink = WeblinkMetadata.query.filter_by(url=decoded_title).first()
        if weblink:
            print(f"Found weblink to delete: {weblink.url}")
            db.session.delete(weblink)
            db.session.commit()
            print(f"âœ… Weblink deleted from database: {decoded_title}")
            
            # ë²¡í„° ë°ì´í„° ì‚­ì œ ì‹œë„
            try:
                result = vector_db_manager.delete_doc_by_title(weblink.title)
                print(f"Vector store deletion result: {result}")
            except Exception as ve:
                print(f"Warning: Failed to delete from vector store: {ve}")
            
            return jsonify({"message": "Weblink deleted successfully"}), 200
            
        # íŒŒì¼ì¸ ê²½ìš° FileMetadataì—ì„œ ê²€ìƒ‰
        file = FileMetadata.query.filter_by(name=decoded_title).first()
        if file:
            print(f"Found file to delete: {file.name}")
            db.session.delete(file)
            db.session.commit()
            print(f"âœ… File deleted from database: {decoded_title}")
            
            # ë²¡í„° ë°ì´í„° ì‚­ì œ ì‹œë„
            try:
                result = vector_db_manager.delete_doc_by_title(file.name)
                print(f"Vector store deletion result: {result}")
            except Exception as ve:
                print(f"Warning: Failed to delete from vector store: {ve}")
            
            return jsonify({"message": "File deleted successfully"}), 200

        print(f"âŒ Document not found in database: {decoded_title}")
        return jsonify({"error": f"Document not found"}), 404

    except Exception as e:
        db.session.rollback()
        error_msg = f"Database error: {str(e)}"
        print(f"âŒ {error_msg}")
        return jsonify({"error": error_msg}), 500
